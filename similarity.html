
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>4. Text Similarity &#8212; EarlyPrint + Python</title>
    
  <link rel="stylesheet" href="_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="3. Working with Metadata, Creating Text Networks" href="metadata.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/eplogo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">EarlyPrint + Python</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   EarlyPrint + Python
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="ep_xml.html">
   1. Parsing
   <em>
    EarlyPrint
   </em>
   XML Texts in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tf_idf.html">
   2. Exploring Vocabulary in
   <em>
    EarlyPrint
   </em>
   using Tf-Idf
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="metadata.html">
   3. Working with Metadata, Creating Text Networks
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   4. Text Similarity
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/similarity.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/earlyprint/jupyterbook"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/earlyprint/jupyterbook/issues/new?title=Issue%20on%20page%20%2Fsimilarity.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/earlyprint/jupyterbook/master?urlpath=tree/similarity.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#get-features">
   4.1. Get Features
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#calculate-distance">
   4.2. Calculate Distance
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reading-results">
   4.3. Reading Results
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="text-similarity">
<h1><span class="section-number">4. </span>Text Similarity<a class="headerlink" href="#text-similarity" title="Permalink to this headline">¶</a></h1>
<p><em>EarlyPrint</em>’s <a class="reference external" href="https://earlyprint.org/lab/tool_discovery_engine.html?which_to_do=find_texts&amp;eebo_tcp_id=A43441&amp;n_results=35&amp;tfidf_weight=6&amp;mallet_weight=6&amp;tag_weight=6">Discovery Engine</a> allows you to find a set of texts similar to any text in our corpus. It does this by using some basic measures of text similarity, and it’s easy to use if you’re interested in finding similar texts across the entire early modern corpus.</p>
<p>But you might be interested in finding similarity across a smaller subset of the corpus. In this tutorial, we’ll calculate similarity across the same set of 1666 texts that we used in the <a class="reference external" href="https://earlyprint.org/jupyterbook/tf_idf.html">TF-IDF tutorial</a>. You could easily do the same with any subset of texts that you’ve gathered using the <a class="reference external" href="https://earlyprint.org/jupyterbook/metadata.html">Metadata tutorial</a>.</p>
<p>This tutorial is meant as a companion to an explanation of text similarity that I wrote for <em>The Programming Historian</em>:</p>
<blockquote>
<div><p><a class="reference external" href="https://programminghistorian.org/en/lessons/common-similarity-measures">Understanding and Using Common Similarity Measures for Text Analysis</a></p>
</div></blockquote>
<p>The article uses the same 1666 corpus as its example, but here we’ll work directly with the <em>EarlyPrint</em> XML instead of with plaintext files. For full explanations of the different similarity measures and how they’re used, please use that piece as a guide.</p>
<p>First, we’ll import necessary libraries. [n.b. In the <em>Programming Historian</em> tutorial, I use <code class="docutils literal notranslate"><span class="pre">scipy</span></code>’s implementation of pairwise distances. For simplicity’s sake, here we’re using Sci-kit Learn’s built-in distance function.]</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">lxml</span> <span class="kn">import</span> <span class="n">etree</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">pairwise_distances</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
</pre></div>
</div>
</div>
</div>
<p>Next we use <code class="docutils literal notranslate"><span class="pre">glob</span></code> to get our list of files and isolate the filekeys to use later. This is the complete list of texts we’re working with in this example. You may have a different directory or filepath for your own files.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Use the glob library to create a list of file names</span>
<span class="n">filenames</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;1666_texts/*.xml&quot;</span><span class="p">)</span>
<span class="c1"># Parse those filenames to create a list of file keys (ID numbers)</span>
<span class="c1"># You&#39;ll use these later on.</span>
<span class="n">filekeys</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">filenames</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">filekeys</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;B02845&#39;, &#39;A51130&#39;, &#39;A36358&#39;, &#39;A28171&#39;, &#39;A51877&#39;, &#39;A60482&#39;, &#39;A32566&#39;, &#39;A35206&#39;, &#39;A35114&#39;, &#39;A32207&#39;, &#39;A39345&#39;, &#39;A25743&#39;, &#39;A86466&#39;, &#39;A61929&#39;, &#39;B03114&#39;, &#39;A32916&#39;, &#39;A70852&#39;, &#39;B01661&#39;, &#39;A61594&#39;, &#39;A35608&#39;, &#39;A64861&#39;, &#39;A61503&#39;, &#39;A79302&#39;, &#39;A62436&#39;, &#39;A38556&#39;, &#39;A32751&#39;, &#39;A63370&#39;, &#39;A57484&#39;, &#39;A92820&#39;, &#39;A39246&#39;, &#39;A87622&#39;, &#39;A66752&#39;, &#39;A26426&#39;, &#39;A26249&#39;, &#39;A55410&#39;, &#39;A46087&#39;, &#39;A31237&#39;, &#39;A61867&#39;, &#39;A61891&#39;, &#39;B05835&#39;, &#39;A28989&#39;, &#39;A31124&#39;, &#39;A80818&#39;, &#39;A65296&#39;, &#39;A30203&#39;, &#39;A55387&#39;, &#39;A59325&#39;, &#39;B06022&#39;, &#39;A56381&#39;, &#39;A61600&#39;, &#39;A66777&#39;, &#39;A39714&#39;, &#39;A44801&#39;, &#39;A71109&#39;, &#39;A49213&#39;, &#39;A43020&#39;, &#39;A45206&#39;, &#39;A95690&#39;, &#39;A60606&#39;, &#39;A23770&#39;, &#39;A52519&#39;, &#39;A44938&#39;, &#39;A64258&#39;, &#39;A70867&#39;, &#39;A35851&#39;, &#39;A56390&#39;, &#39;B02572&#39;, &#39;A91186&#39;, &#39;A59229&#39;, &#39;B05308&#39;, &#39;A30143&#39;, &#39;A46046&#39;, &#39;B03376&#39;, &#39;B03317&#39;, &#39;A47095&#39;, &#39;B01318&#39;, &#39;B03106&#39;, &#39;A44879&#39;, &#39;A54070&#39;, &#39;A70287&#39;, &#39;A28209&#39;, &#39;B04153&#39;, &#39;A29017&#39;, &#39;A70866&#39;, &#39;A47367&#39;, &#39;A44334&#39;, &#39;B03109&#39;, &#39;B02123&#39;, &#39;A42533&#39;, &#39;A42537&#39;, &#39;A44627&#39;, &#39;A93280&#39;, &#39;A38792&#39;, &#39;B06375&#39;, &#39;A67572&#39;, &#39;A46030&#39;, &#39;A32581&#39;, &#39;A44478&#39;, &#39;A47379&#39;, &#39;A41072&#39;, &#39;A32557&#39;, &#39;A37237&#39;, &#39;A39839&#39;, &#39;B04338&#39;, &#39;A48797&#39;, &#39;B03631&#39;, &#39;A46137&#39;, &#39;A41266&#39;, &#39;A32484&#39;, &#39;A25198&#39;, &#39;A42820&#39;, &#39;A39442&#39;, &#39;A67762&#39;, &#39;A45552&#39;, &#39;A52328&#39;, &#39;A97379&#39;, &#39;A44061&#39;, &#39;A93281&#39;, &#39;A67335&#39;, &#39;A40254&#39;, &#39;A26482&#39;, &#39;B05591&#39;, &#39;A32544&#39;, &#39;B06872&#39;, &#39;A32555&#39;, &#39;A36329&#39;, &#39;A41527&#39;, &#39;B04364&#39;, &#39;A41958&#39;, &#39;A31229&#39;, &#39;A96485&#39;, &#39;A32288&#39;, &#39;A59614&#39;, &#39;A53049&#39;, &#39;A32567&#39;, &#39;A38630&#39;, &#39;A32559&#39;, &#39;A60948&#39;, &#39;A53818&#39;, &#39;A57156&#39;, &#39;A65985&#39;, &#39;A41955&#39;]
</pre></div>
</div>
</div>
</div>
<div class="section" id="get-features">
<h2><span class="section-number">4.1. </span>Get Features<a class="headerlink" href="#get-features" title="Permalink to this headline">¶</a></h2>
<p>In order to measure similarity between texts, you need features of those texts to measure. The <a class="reference external" href="https://earlyprint.org/lab/tool_discovery_engine.html?which_to_do=find_texts&amp;eebo_tcp_id=A43441&amp;n_results=35&amp;tfidf_weight=6&amp;mallet_weight=6&amp;tag_weight=6">Discovery Engine</a> calculates similarity across three distinct sets of features for the same texts: TF-IDF weights for word counts, LDA Topic Modeling results, and XML tag structures. As our example here, we’ll use TF-IDF.</p>
<p>The code below is taken directly from the <a class="reference external" href="https://earlyprint.org/jupyterbook/tf_idf.html">TF-IDF Tutorial</a>, where you’ll find a full explanation of what it does. We loop through each text, extract words, count them, and convert those counts to TF-IDF values. There’s one key difference: below we use <a class="reference external" href="https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm">L2 normalization</a> on our TF-IDF transformation. Normalizing values helps us account for very long or very short texts that may skew our similarity results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create an empty lists to put all our texts into</span>
<span class="n">all_tokenized</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Then you can loop through the files</span>
<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">filenames</span><span class="p">:</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">etree</span><span class="o">.</span><span class="n">XMLParser</span><span class="p">(</span><span class="n">collect_ids</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># Create a parse object that skips XML IDs (in this case they just slow things down)</span>
    <span class="n">tree</span> <span class="o">=</span> <span class="n">etree</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">parser</span><span class="p">)</span> <span class="c1"># Parse each file into an XML tree</span>
    <span class="n">xml</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">getroot</span><span class="p">()</span> <span class="c1"># Get the XML from that tree</span>
    
    <span class="c1"># Now we can use lxml to find all the w tags       </span>
    <span class="n">word_tags</span> <span class="o">=</span> <span class="n">xml</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s2">&quot;.//{*}w&quot;</span><span class="p">)</span>
    <span class="c1"># In this next line you&#39;ll do several things at once to create a list of words for each text</span>
    <span class="c1"># 1. Loop through each word: for word in word_tags</span>
    <span class="c1"># 2. Make sure the tag has a word at all: if word.text != None</span>
    <span class="c1"># 3. Get the regularized form of the word: word.get(&#39;reg&#39;, word.text)</span>
    <span class="c1"># 4. Make sure all the words are in lowercase: .lower()</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;reg&#39;</span><span class="p">,</span> <span class="n">word</span><span class="o">.</span><span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">word_tags</span> <span class="k">if</span> <span class="n">word</span><span class="o">.</span><span class="n">text</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">]</span>
    <span class="c1"># Then we add these results to a master list</span>
    <span class="n">all_tokenized</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
    
<span class="c1"># We can count all the words in each text in one line of code</span>
<span class="n">all_counted</span> <span class="o">=</span> <span class="p">[</span><span class="n">Counter</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">all_tokenized</span><span class="p">]</span>

<span class="c1"># To prepare this data for Tf-Idf Transformation, we need to put into a different form, a DataFrame, using pandas.</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">all_counted</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">filekeys</span><span class="p">)</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># First we need to create an &quot;instance&quot; of the transformer, with the proper settings.</span>
<span class="c1"># Normalization is set to &#39;l2&#39;</span>
<span class="n">tfidf</span> <span class="o">=</span> <span class="n">TfidfTransformer</span><span class="p">(</span><span class="n">norm</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="n">sublinear_tf</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># I am choosing to turn on sublinear term frequency scaling, which takes the log of</span>
<span class="c1"># term frequencies and can help to de-emphasize function words like pronouns and articles. </span>
<span class="c1"># You might make a different choice depending on your corpus.</span>

<span class="c1"># Once we&#39;ve created the instance, we can &quot;transform&quot; our counts</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">tfidf</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># Make results readable using Pandas</span>
<span class="n">readable_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span> <span class="c1"># Convert information back to a DataFrame</span>
<span class="n">readable_results</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="calculate-distance">
<h2><span class="section-number">4.2. </span>Calculate Distance<a class="headerlink" href="#calculate-distance" title="Permalink to this headline">¶</a></h2>
<p>Below we’ll calculate three different distance metrics—euclidean distance, “cityblock” distance, and cosine distance—and create DataFrames for each one. For explanations of each metric, and for a discussion of the difference between similarity and distance, you can refer to <a class="reference external" href="https://programminghistorian.org/en/lessons/common-similarity-measures">The Programming Historian tutorial</a> which goes into these topics in detail.</p>
<p>Euclidean distance is first, because it’s the default in <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">euclidean</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="n">euclidean_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">euclidean</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">euclidean_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>B02845</th>
      <th>A51130</th>
      <th>A36358</th>
      <th>A28171</th>
      <th>A51877</th>
      <th>A60482</th>
      <th>A32566</th>
      <th>A35206</th>
      <th>A35114</th>
      <th>A32207</th>
      <th>...</th>
      <th>A59614</th>
      <th>A53049</th>
      <th>A32567</th>
      <th>A38630</th>
      <th>A32559</th>
      <th>A60948</th>
      <th>A53818</th>
      <th>A57156</th>
      <th>A65985</th>
      <th>A41955</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>B02845</th>
      <td>0.000000</td>
      <td>1.276904</td>
      <td>1.282336</td>
      <td>1.327388</td>
      <td>1.385534</td>
      <td>1.334611</td>
      <td>1.338054</td>
      <td>1.285088</td>
      <td>1.357166</td>
      <td>1.338225</td>
      <td>...</td>
      <td>1.310353</td>
      <td>1.323486</td>
      <td>1.338434</td>
      <td>1.234394</td>
      <td>1.346497</td>
      <td>1.310042</td>
      <td>1.346778</td>
      <td>1.320946</td>
      <td>1.296652</td>
      <td>1.313003</td>
    </tr>
    <tr>
      <th>A51130</th>
      <td>1.276904</td>
      <td>0.000000</td>
      <td>1.200168</td>
      <td>1.197267</td>
      <td>1.380927</td>
      <td>1.244560</td>
      <td>1.325529</td>
      <td>1.246744</td>
      <td>1.300878</td>
      <td>1.318610</td>
      <td>...</td>
      <td>1.285184</td>
      <td>1.209513</td>
      <td>1.317437</td>
      <td>1.229994</td>
      <td>1.336612</td>
      <td>1.218881</td>
      <td>1.346623</td>
      <td>1.226397</td>
      <td>1.197699</td>
      <td>1.221007</td>
    </tr>
    <tr>
      <th>A36358</th>
      <td>1.282336</td>
      <td>1.200168</td>
      <td>0.000000</td>
      <td>1.229307</td>
      <td>1.374540</td>
      <td>1.276676</td>
      <td>1.330634</td>
      <td>1.255257</td>
      <td>1.319624</td>
      <td>1.333068</td>
      <td>...</td>
      <td>1.302456</td>
      <td>1.247914</td>
      <td>1.332685</td>
      <td>1.258395</td>
      <td>1.339762</td>
      <td>1.247283</td>
      <td>1.356161</td>
      <td>1.249754</td>
      <td>1.203273</td>
      <td>1.266901</td>
    </tr>
    <tr>
      <th>A28171</th>
      <td>1.327388</td>
      <td>1.197267</td>
      <td>1.229307</td>
      <td>0.000000</td>
      <td>1.377672</td>
      <td>1.108460</td>
      <td>1.343706</td>
      <td>1.276891</td>
      <td>1.237915</td>
      <td>1.336067</td>
      <td>...</td>
      <td>1.294902</td>
      <td>1.098583</td>
      <td>1.332020</td>
      <td>1.289052</td>
      <td>1.350955</td>
      <td>1.172351</td>
      <td>1.350303</td>
      <td>1.132169</td>
      <td>1.137134</td>
      <td>1.186429</td>
    </tr>
    <tr>
      <th>A51877</th>
      <td>1.385534</td>
      <td>1.380927</td>
      <td>1.374540</td>
      <td>1.377672</td>
      <td>0.000000</td>
      <td>1.382244</td>
      <td>1.380671</td>
      <td>1.364325</td>
      <td>1.382631</td>
      <td>1.364649</td>
      <td>...</td>
      <td>1.362772</td>
      <td>1.384687</td>
      <td>1.322868</td>
      <td>1.376365</td>
      <td>1.373189</td>
      <td>1.370114</td>
      <td>1.380516</td>
      <td>1.375525</td>
      <td>1.386100</td>
      <td>1.371331</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>A60948</th>
      <td>1.310042</td>
      <td>1.218881</td>
      <td>1.247283</td>
      <td>1.172351</td>
      <td>1.370114</td>
      <td>1.236151</td>
      <td>1.313828</td>
      <td>1.274511</td>
      <td>1.293992</td>
      <td>1.311999</td>
      <td>...</td>
      <td>1.273916</td>
      <td>1.220130</td>
      <td>1.307373</td>
      <td>1.277805</td>
      <td>1.329701</td>
      <td>0.000000</td>
      <td>1.333518</td>
      <td>1.195987</td>
      <td>1.235246</td>
      <td>1.221432</td>
    </tr>
    <tr>
      <th>A53818</th>
      <td>1.346778</td>
      <td>1.346623</td>
      <td>1.356161</td>
      <td>1.350303</td>
      <td>1.380516</td>
      <td>1.360853</td>
      <td>1.313472</td>
      <td>1.335803</td>
      <td>1.371737</td>
      <td>1.310435</td>
      <td>...</td>
      <td>1.327658</td>
      <td>1.363753</td>
      <td>1.300872</td>
      <td>1.345072</td>
      <td>1.345671</td>
      <td>1.333518</td>
      <td>0.000000</td>
      <td>1.342397</td>
      <td>1.358598</td>
      <td>1.337482</td>
    </tr>
    <tr>
      <th>A57156</th>
      <td>1.320946</td>
      <td>1.226397</td>
      <td>1.249754</td>
      <td>1.132169</td>
      <td>1.375525</td>
      <td>1.216030</td>
      <td>1.327618</td>
      <td>1.286547</td>
      <td>1.274297</td>
      <td>1.311981</td>
      <td>...</td>
      <td>1.291568</td>
      <td>1.230670</td>
      <td>1.311937</td>
      <td>1.289614</td>
      <td>1.338420</td>
      <td>1.195987</td>
      <td>1.342397</td>
      <td>0.000000</td>
      <td>1.211370</td>
      <td>1.222339</td>
    </tr>
    <tr>
      <th>A65985</th>
      <td>1.296652</td>
      <td>1.197699</td>
      <td>1.203273</td>
      <td>1.137134</td>
      <td>1.386100</td>
      <td>1.233905</td>
      <td>1.345823</td>
      <td>1.261121</td>
      <td>1.305451</td>
      <td>1.333307</td>
      <td>...</td>
      <td>1.301967</td>
      <td>1.222347</td>
      <td>1.332329</td>
      <td>1.264718</td>
      <td>1.353246</td>
      <td>1.235246</td>
      <td>1.358598</td>
      <td>1.211370</td>
      <td>0.000000</td>
      <td>1.232445</td>
    </tr>
    <tr>
      <th>A41955</th>
      <td>1.313003</td>
      <td>1.221007</td>
      <td>1.266901</td>
      <td>1.186429</td>
      <td>1.371331</td>
      <td>1.201298</td>
      <td>1.318800</td>
      <td>1.282141</td>
      <td>1.282425</td>
      <td>1.316022</td>
      <td>...</td>
      <td>1.251783</td>
      <td>1.190574</td>
      <td>1.316063</td>
      <td>1.290598</td>
      <td>1.335526</td>
      <td>1.221432</td>
      <td>1.337482</td>
      <td>1.222339</td>
      <td>1.232445</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
<p>142 rows × 142 columns</p>
</div></div></div>
</div>
<p>Next is cityblock distance:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cityblock</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;cityblock&#39;</span><span class="p">)</span>
<span class="n">cityblock_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cityblock</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">cityblock_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>B02845</th>
      <th>A51130</th>
      <th>A36358</th>
      <th>A28171</th>
      <th>A51877</th>
      <th>A60482</th>
      <th>A32566</th>
      <th>A35206</th>
      <th>A35114</th>
      <th>A32207</th>
      <th>...</th>
      <th>A59614</th>
      <th>A53049</th>
      <th>A32567</th>
      <th>A38630</th>
      <th>A32559</th>
      <th>A60948</th>
      <th>A53818</th>
      <th>A57156</th>
      <th>A65985</th>
      <th>A41955</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>B02845</th>
      <td>0.000000</td>
      <td>55.729687</td>
      <td>51.974010</td>
      <td>87.676697</td>
      <td>28.857979</td>
      <td>88.715280</td>
      <td>27.394476</td>
      <td>38.905840</td>
      <td>85.810841</td>
      <td>29.641572</td>
      <td>...</td>
      <td>34.261523</td>
      <td>83.708689</td>
      <td>29.228824</td>
      <td>31.819858</td>
      <td>28.179513</td>
      <td>51.192696</td>
      <td>26.983699</td>
      <td>55.597272</td>
      <td>65.165487</td>
      <td>64.106420</td>
    </tr>
    <tr>
      <th>A51130</th>
      <td>55.729687</td>
      <td>0.000000</td>
      <td>64.822780</td>
      <td>91.902515</td>
      <td>55.152083</td>
      <td>97.926767</td>
      <td>53.550342</td>
      <td>59.311930</td>
      <td>101.112287</td>
      <td>55.056478</td>
      <td>...</td>
      <td>57.298261</td>
      <td>89.232443</td>
      <td>54.486365</td>
      <td>55.686694</td>
      <td>54.017029</td>
      <td>64.833257</td>
      <td>53.223271</td>
      <td>67.947342</td>
      <td>74.297465</td>
      <td>74.267718</td>
    </tr>
    <tr>
      <th>A36358</th>
      <td>51.974010</td>
      <td>64.822780</td>
      <td>0.000000</td>
      <td>92.879475</td>
      <td>50.456637</td>
      <td>98.423786</td>
      <td>49.290019</td>
      <td>55.873211</td>
      <td>99.577443</td>
      <td>51.205557</td>
      <td>...</td>
      <td>54.612407</td>
      <td>90.693265</td>
      <td>50.681598</td>
      <td>52.951746</td>
      <td>49.793157</td>
      <td>63.913262</td>
      <td>49.260386</td>
      <td>66.967821</td>
      <td>72.675023</td>
      <td>75.664139</td>
    </tr>
    <tr>
      <th>A28171</th>
      <td>87.676697</td>
      <td>91.902515</td>
      <td>92.879475</td>
      <td>0.000000</td>
      <td>84.423598</td>
      <td>97.693334</td>
      <td>83.580663</td>
      <td>89.582403</td>
      <td>113.942085</td>
      <td>85.058437</td>
      <td>...</td>
      <td>86.391556</td>
      <td>93.869316</td>
      <td>84.456824</td>
      <td>87.392112</td>
      <td>83.996037</td>
      <td>86.722342</td>
      <td>83.022954</td>
      <td>84.980525</td>
      <td>91.087179</td>
      <td>92.806112</td>
    </tr>
    <tr>
      <th>A51877</th>
      <td>28.857979</td>
      <td>55.152083</td>
      <td>50.456637</td>
      <td>84.423598</td>
      <td>0.000000</td>
      <td>84.998300</td>
      <td>21.284498</td>
      <td>36.366100</td>
      <td>80.559471</td>
      <td>22.910382</td>
      <td>...</td>
      <td>30.387239</td>
      <td>80.807050</td>
      <td>21.801254</td>
      <td>31.711135</td>
      <td>21.450491</td>
      <td>48.118558</td>
      <td>20.612170</td>
      <td>52.296205</td>
      <td>63.950709</td>
      <td>61.429944</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>A60948</th>
      <td>51.192696</td>
      <td>64.833257</td>
      <td>63.913262</td>
      <td>86.722342</td>
      <td>48.118558</td>
      <td>93.510020</td>
      <td>46.450501</td>
      <td>55.058915</td>
      <td>95.593820</td>
      <td>47.952769</td>
      <td>...</td>
      <td>50.148169</td>
      <td>87.239523</td>
      <td>47.347027</td>
      <td>51.897636</td>
      <td>46.965439</td>
      <td>0.000000</td>
      <td>46.041379</td>
      <td>61.250843</td>
      <td>74.062192</td>
      <td>70.586691</td>
    </tr>
    <tr>
      <th>A53818</th>
      <td>26.983699</td>
      <td>53.223271</td>
      <td>49.260386</td>
      <td>83.022954</td>
      <td>20.612170</td>
      <td>83.814390</td>
      <td>18.472033</td>
      <td>34.861591</td>
      <td>79.653275</td>
      <td>20.768595</td>
      <td>...</td>
      <td>28.371200</td>
      <td>79.604647</td>
      <td>19.847619</td>
      <td>29.867763</td>
      <td>20.029364</td>
      <td>46.041379</td>
      <td>0.000000</td>
      <td>50.393832</td>
      <td>62.340451</td>
      <td>59.569190</td>
    </tr>
    <tr>
      <th>A57156</th>
      <td>55.597272</td>
      <td>67.947342</td>
      <td>66.967821</td>
      <td>84.980525</td>
      <td>52.296205</td>
      <td>93.743856</td>
      <td>50.875350</td>
      <td>59.830095</td>
      <td>96.076857</td>
      <td>51.987987</td>
      <td>...</td>
      <td>55.057412</td>
      <td>90.299650</td>
      <td>51.697250</td>
      <td>56.405675</td>
      <td>51.460379</td>
      <td>61.250843</td>
      <td>50.393832</td>
      <td>0.000000</td>
      <td>74.114647</td>
      <td>72.968215</td>
    </tr>
    <tr>
      <th>A65985</th>
      <td>65.165487</td>
      <td>74.297465</td>
      <td>72.675023</td>
      <td>91.087179</td>
      <td>63.950709</td>
      <td>102.454809</td>
      <td>62.790934</td>
      <td>68.307826</td>
      <td>107.964458</td>
      <td>64.138075</td>
      <td>...</td>
      <td>66.734171</td>
      <td>96.003553</td>
      <td>63.719435</td>
      <td>65.396731</td>
      <td>63.271991</td>
      <td>74.062192</td>
      <td>62.340451</td>
      <td>74.114647</td>
      <td>0.000000</td>
      <td>81.737142</td>
    </tr>
    <tr>
      <th>A41955</th>
      <td>64.106420</td>
      <td>74.267718</td>
      <td>75.664139</td>
      <td>92.806112</td>
      <td>61.429944</td>
      <td>95.660497</td>
      <td>59.957683</td>
      <td>67.835311</td>
      <td>102.003090</td>
      <td>61.365149</td>
      <td>...</td>
      <td>61.312909</td>
      <td>89.242595</td>
      <td>60.927150</td>
      <td>65.207456</td>
      <td>60.508757</td>
      <td>70.586691</td>
      <td>59.569190</td>
      <td>72.968215</td>
      <td>81.737142</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
<p>142 rows × 142 columns</p>
</div></div></div>
</div>
<p>And finally cosine distance, which is usually (but not always) preferrable for text similarity:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cosine</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;cosine&#39;</span><span class="p">)</span>
<span class="n">cosine_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cosine</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">cosine_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>B02845</th>
      <th>A51130</th>
      <th>A36358</th>
      <th>A28171</th>
      <th>A51877</th>
      <th>A60482</th>
      <th>A32566</th>
      <th>A35206</th>
      <th>A35114</th>
      <th>A32207</th>
      <th>...</th>
      <th>A59614</th>
      <th>A53049</th>
      <th>A32567</th>
      <th>A38630</th>
      <th>A32559</th>
      <th>A60948</th>
      <th>A53818</th>
      <th>A57156</th>
      <th>A65985</th>
      <th>A41955</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>B02845</th>
      <td>0.000000</td>
      <td>0.815242</td>
      <td>0.822193</td>
      <td>0.880979</td>
      <td>0.959852</td>
      <td>0.890593</td>
      <td>0.895194</td>
      <td>0.825725</td>
      <td>0.920950</td>
      <td>0.895423</td>
      <td>...</td>
      <td>0.858512</td>
      <td>0.875808</td>
      <td>0.895703</td>
      <td>0.761865</td>
      <td>0.906527</td>
      <td>0.858105</td>
      <td>0.906906</td>
      <td>0.872449</td>
      <td>0.840653</td>
      <td>0.861988</td>
    </tr>
    <tr>
      <th>A51130</th>
      <td>0.815242</td>
      <td>0.000000</td>
      <td>0.720202</td>
      <td>0.716725</td>
      <td>0.953480</td>
      <td>0.774465</td>
      <td>0.878513</td>
      <td>0.777185</td>
      <td>0.846142</td>
      <td>0.869367</td>
      <td>...</td>
      <td>0.825849</td>
      <td>0.731461</td>
      <td>0.867820</td>
      <td>0.756443</td>
      <td>0.893266</td>
      <td>0.742836</td>
      <td>0.906697</td>
      <td>0.752025</td>
      <td>0.717242</td>
      <td>0.745429</td>
    </tr>
    <tr>
      <th>A36358</th>
      <td>0.822193</td>
      <td>0.720202</td>
      <td>0.000000</td>
      <td>0.755597</td>
      <td>0.944681</td>
      <td>0.814951</td>
      <td>0.885293</td>
      <td>0.787835</td>
      <td>0.870704</td>
      <td>0.888536</td>
      <td>...</td>
      <td>0.848196</td>
      <td>0.778645</td>
      <td>0.888025</td>
      <td>0.791779</td>
      <td>0.897481</td>
      <td>0.777857</td>
      <td>0.919586</td>
      <td>0.780943</td>
      <td>0.723933</td>
      <td>0.802519</td>
    </tr>
    <tr>
      <th>A28171</th>
      <td>0.880979</td>
      <td>0.716725</td>
      <td>0.755597</td>
      <td>0.000000</td>
      <td>0.948989</td>
      <td>0.614342</td>
      <td>0.902773</td>
      <td>0.815225</td>
      <td>0.766216</td>
      <td>0.892537</td>
      <td>...</td>
      <td>0.838385</td>
      <td>0.603443</td>
      <td>0.887138</td>
      <td>0.830828</td>
      <td>0.912540</td>
      <td>0.687204</td>
      <td>0.911659</td>
      <td>0.640904</td>
      <td>0.646536</td>
      <td>0.703807</td>
    </tr>
    <tr>
      <th>A51877</th>
      <td>0.959852</td>
      <td>0.953480</td>
      <td>0.944681</td>
      <td>0.948989</td>
      <td>0.000000</td>
      <td>0.955299</td>
      <td>0.953126</td>
      <td>0.930692</td>
      <td>0.955834</td>
      <td>0.931133</td>
      <td>...</td>
      <td>0.928574</td>
      <td>0.958679</td>
      <td>0.874990</td>
      <td>0.947190</td>
      <td>0.942824</td>
      <td>0.938607</td>
      <td>0.952913</td>
      <td>0.946034</td>
      <td>0.960637</td>
      <td>0.940274</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>A60948</th>
      <td>0.858105</td>
      <td>0.742836</td>
      <td>0.777857</td>
      <td>0.687204</td>
      <td>0.938607</td>
      <td>0.764035</td>
      <td>0.863072</td>
      <td>0.812189</td>
      <td>0.837208</td>
      <td>0.860671</td>
      <td>...</td>
      <td>0.811431</td>
      <td>0.744358</td>
      <td>0.854613</td>
      <td>0.816393</td>
      <td>0.884052</td>
      <td>0.000000</td>
      <td>0.889135</td>
      <td>0.715193</td>
      <td>0.762917</td>
      <td>0.745949</td>
    </tr>
    <tr>
      <th>A53818</th>
      <td>0.906906</td>
      <td>0.906697</td>
      <td>0.919586</td>
      <td>0.911659</td>
      <td>0.952913</td>
      <td>0.925960</td>
      <td>0.862604</td>
      <td>0.892185</td>
      <td>0.940831</td>
      <td>0.858620</td>
      <td>...</td>
      <td>0.881337</td>
      <td>0.929910</td>
      <td>0.846134</td>
      <td>0.904610</td>
      <td>0.905416</td>
      <td>0.889135</td>
      <td>0.000000</td>
      <td>0.901015</td>
      <td>0.922894</td>
      <td>0.894429</td>
    </tr>
    <tr>
      <th>A57156</th>
      <td>0.872449</td>
      <td>0.752025</td>
      <td>0.780943</td>
      <td>0.640904</td>
      <td>0.946034</td>
      <td>0.739364</td>
      <td>0.881285</td>
      <td>0.827602</td>
      <td>0.811916</td>
      <td>0.860647</td>
      <td>...</td>
      <td>0.834074</td>
      <td>0.757275</td>
      <td>0.860590</td>
      <td>0.831553</td>
      <td>0.895684</td>
      <td>0.715193</td>
      <td>0.901015</td>
      <td>0.000000</td>
      <td>0.733708</td>
      <td>0.747056</td>
    </tr>
    <tr>
      <th>A65985</th>
      <td>0.840653</td>
      <td>0.717242</td>
      <td>0.723933</td>
      <td>0.646536</td>
      <td>0.960637</td>
      <td>0.761261</td>
      <td>0.905620</td>
      <td>0.795213</td>
      <td>0.852101</td>
      <td>0.888854</td>
      <td>...</td>
      <td>0.847559</td>
      <td>0.747067</td>
      <td>0.887550</td>
      <td>0.799756</td>
      <td>0.915638</td>
      <td>0.762917</td>
      <td>0.922894</td>
      <td>0.733708</td>
      <td>0.000000</td>
      <td>0.759460</td>
    </tr>
    <tr>
      <th>A41955</th>
      <td>0.861988</td>
      <td>0.745429</td>
      <td>0.802519</td>
      <td>0.703807</td>
      <td>0.940274</td>
      <td>0.721558</td>
      <td>0.869617</td>
      <td>0.821942</td>
      <td>0.822306</td>
      <td>0.865957</td>
      <td>...</td>
      <td>0.783481</td>
      <td>0.708734</td>
      <td>0.866011</td>
      <td>0.832822</td>
      <td>0.891814</td>
      <td>0.745949</td>
      <td>0.894429</td>
      <td>0.747056</td>
      <td>0.759460</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
<p>142 rows × 142 columns</p>
</div></div></div>
</div>
</div>
<div class="section" id="reading-results">
<h2><span class="section-number">4.3. </span>Reading Results<a class="headerlink" href="#reading-results" title="Permalink to this headline">¶</a></h2>
<p>Now that we have DataFrames of all our distance results, we can easily look at the texts that are most similar (i.e. closest in distance) to a text of our choice. We’ll use the same example as in the TF-IDF tutorial: Margaret Cavendish’s <em>The Blazing World</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">top5_cosine</span> <span class="o">=</span> <span class="n">cosine_df</span><span class="o">.</span><span class="n">nsmallest</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;A53049&#39;</span><span class="p">)[</span><span class="s1">&#39;A53049&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">top5_cosine</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>A29017    0.570971
A28171    0.603443
A57484    0.620828
A60482    0.635795
A56381    0.637656
Name: A53049, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>We now have a list of text IDs and their cosine similarities, but this list is hard to interpret without more information. We can use the techniques from the <a class="reference external" href="https://earlyprint.org/jupyterbook/metadata.html">Metadata tutorial</a> to get a DataFrame of metadata for all the 1666 texts:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the full list of metadata files</span>
<span class="c1"># (You&#39;ll change this line based on where the files are on your computer)</span>
<span class="n">metadata_files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;../../epmetadata/header/*.xml&quot;</span><span class="p">)</span>
<span class="n">nsmap</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;tei&#39;</span><span class="p">:</span> <span class="s1">&#39;http://www.tei-c.org/ns/1.0&#39;</span><span class="p">}</span>

<span class="n">all_metadata</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># Empty list for data</span>
<span class="n">index</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># Empty list for TCP IDs</span>
<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">metadata_files</span><span class="p">:</span> <span class="c1"># Loop through each file</span>
    <span class="n">tcp_id</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># Get TCP ID from filename</span>
    <span class="k">if</span> <span class="n">tcp_id</span> <span class="ow">in</span> <span class="n">filekeys</span><span class="p">:</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="n">etree</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">parser</span><span class="p">)</span> <span class="c1"># Create lxml tree for metadata</span>
        <span class="n">title</span> <span class="o">=</span> <span class="n">metadata</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;.//tei:sourceDesc//tei:title&quot;</span><span class="p">,</span> <span class="n">namespaces</span><span class="o">=</span><span class="n">nsmap</span><span class="p">)</span><span class="o">.</span><span class="n">text</span> <span class="c1"># Get title</span>

        <span class="c1"># Get author (if there is one)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">author</span> <span class="o">=</span> <span class="n">metadata</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;.//tei:sourceDesc//tei:author&quot;</span><span class="p">,</span> <span class="n">namespaces</span><span class="o">=</span><span class="n">nsmap</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="n">author</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Get date (if there is one that isn&#39;t a range)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">date</span> <span class="o">=</span> <span class="n">metadata</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;.//tei:sourceDesc//tei:date&quot;</span><span class="p">,</span> <span class="n">namespaces</span><span class="o">=</span><span class="n">nsmap</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;when&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="n">date</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Add dictionary of data to data list</span>
        <span class="n">all_metadata</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;title&#39;</span><span class="p">:</span><span class="n">title</span><span class="p">,</span><span class="s1">&#39;author&#39;</span><span class="p">:</span><span class="n">author</span><span class="p">,</span><span class="s1">&#39;date&#39;</span><span class="p">:</span><span class="n">date</span><span class="p">})</span>

        <span class="c1"># Add TCP ID to index list</span>
        <span class="n">index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tcp_id</span><span class="p">)</span>


<span class="c1"># Create DataFrame with data and indices</span>
<span class="n">metadata_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">all_metadata</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">)</span>
<span class="n">metadata_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>author</th>
      <th>date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>A48797</th>
      <td>Wonders no miracles, or, Mr. Valentine Greatra...</td>
      <td>Lloyd, David, 1635-1692.</td>
      <td>1666</td>
    </tr>
    <tr>
      <th>A44938</th>
      <td>A fast-sermon, preached to the Lords in the Hi...</td>
      <td>Hall, George, 1612?-1668.</td>
      <td>1666</td>
    </tr>
    <tr>
      <th>A35608</th>
      <td>The Case of Cornelius Bee and his partners Ric...</td>
      <td>None</td>
      <td>1666</td>
    </tr>
    <tr>
      <th>A52328</th>
      <td>The pernicious consequences of the new heresie...</td>
      <td>Nicole, Pierre, 1625-1695.</td>
      <td>1666</td>
    </tr>
    <tr>
      <th>A26426</th>
      <td>Advertisement be [sic] Agnes Campbel relict of...</td>
      <td>Campbel, Agnes.</td>
      <td>1666</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>A66752</th>
      <td>Ecchoes from the sixth trumpet. The first part...</td>
      <td>Wither, George, 1588-1667.</td>
      <td>1666</td>
    </tr>
    <tr>
      <th>A30143</th>
      <td>Grace abounding to the chief of sinners, or, A...</td>
      <td>Bunyan, John, 1628-1688.</td>
      <td>1666</td>
    </tr>
    <tr>
      <th>A32207</th>
      <td>His Majesties declaration Charles R.</td>
      <td>England and Wales. Sovereign (1660-1685 : Char...</td>
      <td>1666</td>
    </tr>
    <tr>
      <th>A49213</th>
      <td>The French Kings declaration of a vvar against...</td>
      <td>France. Sovereign (1643-1715 : Louis XIV)</td>
      <td>1666</td>
    </tr>
    <tr>
      <th>A23770</th>
      <td>A sermon preach'd before the King, Decemb. 31,...</td>
      <td>Allestree, Richard, 1619-1681.</td>
      <td>1666</td>
    </tr>
  </tbody>
</table>
<p>142 rows × 3 columns</p>
</div></div></div>
</div>
<p>And we can combine this with our cosine distance results to see the metadata for the texts most similar to <em>The Blazing World</em>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">metadata_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">top5_cosine</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;author&#39;</span><span class="p">,</span><span class="s1">&#39;title&#39;</span><span class="p">,</span><span class="s1">&#39;date&#39;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>author</th>
      <th>title</th>
      <th>date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>A29017</th>
      <td>Boyle, Robert, 1627-1691.</td>
      <td>The origine of formes and qualities, (accordin...</td>
      <td>1666</td>
    </tr>
    <tr>
      <th>A28171</th>
      <td>Binning, Hugh, 1627-1653.</td>
      <td>The common principiles of Christian religion c...</td>
      <td>1667</td>
    </tr>
    <tr>
      <th>A57484</th>
      <td>Rochefort, César de, b. 1605.</td>
      <td>The history of the Caribby-islands, viz, Barba...</td>
      <td>1666</td>
    </tr>
    <tr>
      <th>A60482</th>
      <td>Smith, John, 1630-1679.</td>
      <td>Gērochomia vasilikē King Solomons portraiture ...</td>
      <td>1666</td>
    </tr>
    <tr>
      <th>A56381</th>
      <td>Parker, Samuel, 1640-1688.</td>
      <td>An account of the nature and extent of the div...</td>
      <td>1666</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>You now have all the tools you need to creat your own mini <a class="reference external" href="https://earlyprint.org/lab/tool_discovery_engine.html?which_to_do=find_texts&amp;eebo_tcp_id=A43441&amp;n_results=35&amp;tfidf_weight=6&amp;mallet_weight=6&amp;tag_weight=6">Discovery Engine</a>, one focused on exactly the texts you care most about. For more on how to interpret these results and things to watch out for when calculating similarity, refer again to <a class="reference external" href="https://programminghistorian.org/en/lessons/common-similarity-measures">The Programming Historian</a>.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="metadata.html" title="previous page"><span class="section-number">3. </span>Working with Metadata, Creating Text Networks</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By John R. Ladd<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>